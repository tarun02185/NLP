{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtDl4zrbk8UJ",
        "outputId": "2ef2542c-ef19-41a4-e15c-5e6639d05f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import random, math, itertools\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, Tuple, Generator, List\n",
        "import numpy as np\n",
        "\n",
        "INPUT_SOURCE_PATH = \"/content/drive/MyDrive/dataset/sentences_of_hindi_corpus_1.txt\"\n",
        "TRAIN_FILENAME = \"train.txt\"\n",
        "VAL_FILENAME = \"val.txt\"\n",
        "TEST_FILENAME = \"test.txt\"\n",
        "\n",
        "MAX_SENTENCE_LIMIT = 1000000\n",
        "MAX_N = 4\n",
        "START_TOKEN = \"<s>\"\n",
        "END_TOKEN = \"</s>\"\n",
        "\n",
        "VAL_SIZE = 1000\n",
        "TEST_SIZE = 1000\n",
        "STEPS = [i / 10 for i in range(11)]\n"
      ],
      "metadata": {
        "id": "1kmWwrWrk-LT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def stream_tokens(path: Path) -> Generator[str, None, None]:\n",
        "    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                yield START_TOKEN\n",
        "                for tok in line.split():\n",
        "                    t = tok.strip()\n",
        "                    if t:\n",
        "                        yield t\n",
        "                yield END_TOKEN\n",
        "\n",
        "def create_data_splits(input_path: str, max_limit: int):\n",
        "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        all_sentences = [line for line in itertools.islice(f, max_limit)]\n",
        "\n",
        "    random.seed(42)\n",
        "    random.shuffle(all_sentences)\n",
        "\n",
        "    val_sentences = all_sentences[:VAL_SIZE]\n",
        "    test_sentences = all_sentences[VAL_SIZE:VAL_SIZE+TEST_SIZE]\n",
        "    train_sentences = all_sentences[VAL_SIZE+TEST_SIZE:]\n",
        "\n",
        "    with open(TRAIN_FILENAME, \"w\", encoding=\"utf-8\") as f: f.writelines(train_sentences)\n",
        "    with open(VAL_FILENAME, \"w\", encoding=\"utf-8\") as f: f.writelines(val_sentences)\n",
        "    with open(TEST_FILENAME, \"w\", encoding=\"utf-8\") as f: f.writelines(test_sentences)\n",
        "\n",
        "create_data_splits(INPUT_SOURCE_PATH, MAX_SENTENCE_LIMIT)\n",
        "print(\"Data split done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr4HRa7Mk-H4",
        "outputId": "0434665f-135e-4203-9f86-15796d6f661e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Optimized N-gram Counter\n",
        "def count_ngrams(tokens: List[str], max_n: int = 4):\n",
        "    counts = {n: defaultdict(int) for n in range(1, max_n+1)}\n",
        "    window = []\n",
        "\n",
        "    for tok in tokens:\n",
        "        counts[1][(tok,)] += 1\n",
        "        window.append(tok)\n",
        "\n",
        "        for n in range(2, max_n+1):\n",
        "            if len(window) >= n:\n",
        "                gram = tuple(window[-n:])\n",
        "                counts[n][gram] += 1\n",
        "\n",
        "        if len(window) > max_n:\n",
        "            window.pop(0)\n",
        "\n",
        "    return counts\n",
        "\n",
        "train_tokens = list(stream_tokens(Path(TRAIN_FILENAME)))\n",
        "train_counts = count_ngrams(train_tokens)\n",
        "\n",
        "vocab = set(train_tokens)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "print(\"N-gram counting done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xbkxaGhk-FQ",
        "outputId": "1f10653a-68ff-4f87-efd4-e4a5a13fa759"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram counting done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Good-Turing\n",
        "def good_turing_probs(counts: Dict[Tuple[str, ...], int], n: int, vocab_size: int):\n",
        "    Nc = Counter(counts.values())\n",
        "    N = sum(counts.values())\n",
        "    N1 = Nc.get(1, 0)\n",
        "\n",
        "    if n == 1:\n",
        "        U = len(counts)\n",
        "        num_unseen = max(vocab_size - U, 1)\n",
        "    else:\n",
        "        num_unseen = max(1, vocab_size**n - len(counts))\n",
        "\n",
        "    P_unseen_individual = N1 / (N * num_unseen)\n",
        "\n",
        "    by_count = defaultdict(list)\n",
        "    for gram, c in counts.items():\n",
        "        by_count[c].append(gram)\n",
        "\n",
        "    max_c = max(Nc)\n",
        "    cstar_table = {}\n",
        "    probs = {}\n",
        "\n",
        "    for c in range(max_c + 1):\n",
        "        Nc_c = Nc.get(c, 0)\n",
        "        Nc1 = Nc.get(c + 1, 0)\n",
        "\n",
        "        if c == 0:\n",
        "            cstar = 0.0\n",
        "        elif Nc_c > 0 and Nc1 > 0:\n",
        "            cstar = (c + 1) * Nc1 / Nc_c\n",
        "        else:\n",
        "            cstar = float(c)\n",
        "\n",
        "        cstar_table[c] = (Nc_c, cstar)\n",
        "\n",
        "        if c in by_count and c > 0:\n",
        "            p_star = cstar / N\n",
        "            for gram in by_count[c]:\n",
        "                probs[gram] = p_star\n",
        "\n",
        "    return probs, P_unseen_individual, cstar_table\n",
        "\n",
        "gt_probs_models = {}\n",
        "p_unseen_map = {}\n",
        "\n",
        "for n in range(1, MAX_N+1):\n",
        "    print(\"Good-Turing for n =\", n)\n",
        "    probs, p_u, cstar_table = good_turing_probs(train_counts[n], n, vocab_size)\n",
        "    gt_probs_models[n] = probs\n",
        "    p_unseen_map[n] = p_u\n",
        "\n",
        "print(\"Good-Turing done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U4vPi6lk-CS",
        "outputId": "8fd5dd99-95e1-4dda-8b91-168425b1097c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good-Turing for n = 1\n",
            "Good-Turing for n = 2\n",
            "Good-Turing for n = 3\n",
            "Good-Turing for n = 4\n",
            "Good-Turing done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 100 Table\n",
        "Nc_unigram = Counter(train_counts[1].values())\n",
        "cstar_unigram = {}\n",
        "\n",
        "max_c = max(Nc_unigram)\n",
        "for c in range(max_c+1):\n",
        "    Nc_c = Nc_unigram.get(c,0)\n",
        "    Nc1 = Nc_unigram.get(c+1,0)\n",
        "    if c==0:\n",
        "        cstar = p_unseen_map[1]\n",
        "    elif Nc_c>0 and Nc1>0:\n",
        "        cstar = (c+1)*Nc1/Nc_c\n",
        "    else:\n",
        "        cstar = float(c)\n",
        "    cstar_unigram[c] = (Nc_c, cstar)\n",
        "\n",
        "print(\"C (MLE)\\tNc\\tC*\")\n",
        "print(f\"0\\t{cstar_unigram[0][0]}\\t{cstar_unigram[0][1]:.6f}\")\n",
        "\n",
        "items = sorted([(c, Nc_unigram[c]) for c in Nc_unigram if c>0], key=lambda x: -x[1])[:99]\n",
        "for c, Nc_val in items:\n",
        "    print(f\"{c}\\t{Nc_val}\\t{cstar_unigram[c][1]:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqfi_SQTk9_V",
        "outputId": "d8a9f60c-edd5-4309-f291-1f97b38a8616"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C (MLE)\tNc\tC*\n",
            "0\t0\t0.007399\n",
            "1\t141131\t0.470046\n",
            "2\t33169\t1.407610\n",
            "3\t15563\t2.449656\n",
            "4\t9531\t3.418319\n",
            "5\t6516\t4.364641\n",
            "6\t4740\t5.607384\n",
            "7\t3797\t6.455623\n",
            "8\t3064\t7.499021\n",
            "9\t2553\t8.139444\n",
            "10\t2078\t9.983638\n",
            "11\t1886\t10.759279\n",
            "12\t1691\t11.370195\n",
            "13\t1479\t11.898580\n",
            "14\t1257\t13.078759\n",
            "15\t1096\t15.036496\n",
            "16\t1030\t15.993204\n",
            "17\t969\t16.179567\n",
            "18\t871\t17.822044\n",
            "19\t817\t18.188494\n",
            "20\t743\t19.728129\n",
            "21\t698\t19.762178\n",
            "22\t627\t20.432217\n",
            "24\t584\t21.104452\n",
            "23\t557\t25.163375\n",
            "26\t502\t24.956175\n",
            "25\t493\t26.474645\n",
            "28\t473\t26.731501\n",
            "27\t464\t28.543103\n",
            "29\t436\t27.178899\n",
            "30\t395\t30.607595\n",
            "31\t390\t28.307692\n",
            "33\t356\t32.949438\n",
            "34\t345\t31.144928\n",
            "32\t345\t34.052174\n",
            "35\t307\t34.710098\n",
            "36\t296\t34.375000\n",
            "39\t289\t34.048443\n",
            "38\t288\t39.135417\n",
            "37\t275\t39.796364\n",
            "41\t254\t40.677165\n",
            "42\t246\t39.678862\n",
            "40\t246\t42.333333\n",
            "44\t236\t42.711864\n",
            "43\t227\t45.744493\n",
            "48\t227\t43.171806\n",
            "45\t224\t43.741071\n",
            "46\t213\t46.558685\n",
            "47\t211\t51.639810\n",
            "49\t200\t40.000000\n",
            "51\t180\t45.933333\n",
            "53\t178\t50.359551\n",
            "57\t167\t54.526946\n",
            "54\t166\t51.686747\n",
            "50\t160\t57.375000\n",
            "52\t159\t59.333333\n",
            "59\t157\t54.267516\n",
            "58\t157\t59.000000\n",
            "55\t156\t55.282051\n",
            "56\t154\t61.811688\n",
            "60\t142\t52.838028\n",
            "63\t131\t63.022901\n",
            "64\t129\t62.984496\n",
            "66\t128\t61.765625\n",
            "65\t125\t67.584000\n",
            "70\t125\t61.344000\n",
            "61\t123\t61.495935\n",
            "62\t122\t67.647541\n",
            "68\t121\t62.727273\n",
            "67\t118\t69.728814\n",
            "73\t112\t61.446429\n",
            "69\t110\t79.545455\n",
            "76\t109\t55.807339\n",
            "71\t108\t71.333333\n",
            "72\t107\t76.411215\n",
            "80\t105\t70.200000\n",
            "75\t103\t80.427184\n",
            "84\t102\t74.166667\n",
            "82\t93\t68.720430\n",
            "74\t93\t83.064516\n",
            "81\t91\t83.802198\n",
            "85\t89\t77.303371\n",
            "79\t85\t98.823529\n",
            "78\t84\t79.940476\n",
            "89\t84\t82.500000\n",
            "86\t80\t85.912500\n",
            "87\t79\t75.746835\n",
            "77\t79\t82.936709\n",
            "90\t77\t80.363636\n",
            "83\t77\t111.272727\n",
            "106\t76\t73.210526\n",
            "94\t76\t86.250000\n",
            "96\t73\t90.356164\n",
            "99\t72\t97.222222\n",
            "92\t71\t83.830986\n",
            "100\t70\t89.457143\n",
            "112\t69\t93.347826\n",
            "95\t69\t101.565217\n",
            "88\t68\t109.941176\n",
            "102\t68\t89.367647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perplexity\n",
        "def calculate_log_prob(sentences, model_probs, vocab_size, n, punseen):\n",
        "    total_log = 0\n",
        "    total_words = 0\n",
        "\n",
        "    for file_name in sentences:\n",
        "        tokens = list(stream_tokens(Path(file_name)))\n",
        "        total_words += len(tokens)-1\n",
        "\n",
        "        for i in range(1, len(tokens)):\n",
        "            cur_n = min(n, i+1)\n",
        "            gram = tuple(tokens[i-cur_n+1:i+1])\n",
        "            p = model_probs[n].get(gram, punseen)\n",
        "            total_log += math.log(max(p, 1e-12))\n",
        "\n",
        "    ppl = math.exp(-total_log / max(total_words,1))\n",
        "    return total_log, ppl, total_words\n",
        "\n",
        "for n in range(1, MAX_N+1):\n",
        "    for fname, label in [(VAL_FILENAME,\"VAL\"), (TEST_FILENAME,\"TEST\")]:\n",
        "        lp, ppl, tw = calculate_log_prob([fname], gt_probs_models, vocab_size, n, p_unseen_map[n])\n",
        "        print(n, label, lp, ppl, tw)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFA_vRcOk98u",
        "outputId": "93617edd-2fb7-4a0c-8f02-1b6ddf8a4cfb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 VAL -138153.81354047495 1260.160137835918 19352\n",
            "1 TEST -137698.58100238082 1293.470024984462 19218\n",
            "2 VAL -250680.97030591636 422417.7430454817 19352\n",
            "2 TEST -251180.52265973605 474523.158490282 19218\n",
            "3 VAL -360760.0282736218 124772456.42342398 19352\n",
            "3 TEST -361329.77639926795 146367721.97153842 19218\n",
            "4 VAL -438769.8990259785 7027546691.647323 19352\n",
            "4 TEST -438702.05169908085 8202167269.215983 19218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precompute MLE\n",
        "mle = {1:{}, 2:{}, 3:{}, 4:{}}\n",
        "\n",
        "tot1 = sum(train_counts[1].values())\n",
        "for g,c in train_counts[1].items():\n",
        "    mle[1][g] = c / tot1\n",
        "\n",
        "for n in [2,3,4]:\n",
        "    for g,c in train_counts[n].items():\n",
        "        hist = g[:-1]\n",
        "        denom = train_counts[n-1].get(hist,0)\n",
        "        mle[n][g] = c/denom if denom>0 else 0\n"
      ],
      "metadata": {
        "id": "43iEAbZXk953"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare quad validation data\n",
        "val_tokens = list(stream_tokens(Path(VAL_FILENAME)))\n",
        "val_counts = count_ngrams(val_tokens)\n",
        "\n",
        "quad_list = []\n",
        "for gram, count in val_counts[4].items():\n",
        "    w = gram[-1]\n",
        "    p1 = mle[1].get((w,),0)\n",
        "    p2 = mle[2].get(gram[2:],0)\n",
        "    p3 = mle[3].get(gram[1:],0)\n",
        "    p4 = mle[4].get(gram,0)\n",
        "    quad_list.append((count, p1, p2, p3, p4))\n",
        "\n",
        "quad_array = np.array(quad_list)\n",
        "counts = quad_array[:,0]\n",
        "p1s = quad_array[:,1]\n",
        "p2s = quad_array[:,2]\n",
        "p3s = quad_array[:,3]\n",
        "p4s = quad_array[:,4]\n",
        "\n",
        "print(\"Prepared validation quad data.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgvbMH09k93I",
        "outputId": "2866ed31-4a9c-4d83-e6e1-0c922bb5734c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared validation quad data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleted Interpolation\n",
        "best_logprob = -1e300\n",
        "best_lambdas = (0,0,0,0)\n",
        "\n",
        "for l4 in STEPS:\n",
        "    for l3 in STEPS:\n",
        "        for l2 in STEPS:\n",
        "            l1 = 1 - (l4 + l3 + l2)\n",
        "            if l1 < 0: continue\n",
        "\n",
        "            p = l1*p1s + l2*p2s + l3*p3s + l4*p4s\n",
        "            p = np.clip(p, 1e-12, 1)\n",
        "            logprob = np.sum(counts * np.log(p))\n",
        "\n",
        "            if logprob > best_logprob:\n",
        "                best_logprob = logprob\n",
        "                best_lambdas = (l1, l2, l3, l4)\n",
        "\n",
        "print(\"Best lambdas:\", best_lambdas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fIwZsMZk90S",
        "outputId": "76e898bd-041e-4ff3-89f1-34262f1635e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best lambdas: (0.19999999999999996, 0.5, 0.2, 0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_tokens = list(stream_tokens(Path(TEST_FILENAME)))\n",
        "\n",
        "ll = 0\n",
        "total = 0\n",
        "window = []\n",
        "\n",
        "l1,l2,l3,l4 = best_lambdas\n",
        "\n",
        "for tok in test_tokens:\n",
        "    if tok == START_TOKEN:\n",
        "        window = []\n",
        "        continue\n",
        "\n",
        "    total += 1\n",
        "    window.append(tok)\n",
        "\n",
        "    if len(window) >= 4:\n",
        "        gram = tuple(window[-4:])\n",
        "        w = gram[-1]\n",
        "        p4 = mle[4].get(gram,0)\n",
        "        p3 = mle[3].get(gram[1:],0)\n",
        "        p2 = mle[2].get(gram[2:],0)\n",
        "        p1 = mle[1].get((w,),0)\n",
        "        p = l1*p1 + l2*p2 + l3*p3 + l4*p4\n",
        "        ll += math.log(max(p,1e-12))\n",
        "\n",
        "    if len(window)>4:\n",
        "        window.pop(0)\n",
        "\n",
        "ppl = math.exp(-ll/max(total,1))\n",
        "print(\"Test LogP:\", ll)\n",
        "print(\"Test Perplexity:\", ppl)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjMFDRPgk9xR",
        "outputId": "29c1791b-4d0e-467f-bcfc-96f15cabdad8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test LogP: -81423.6035077737\n",
            "Test Perplexity: 87.28326622987194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ktIMH3woSeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}