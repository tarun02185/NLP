{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4835c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35301171",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Sentence\": [\n",
    "        \"Check out https://example.com for more info!\",\n",
    "        \"Order 3 items, get 1 free! Limited offer!!!\",\n",
    "        \"Your package #12345 will arrive tomorrow.\",\n",
    "        \"Win $1000 now, visit http://winbig.com!!!\",\n",
    "        \"Meeting at 3pm, don't forget to bring the files.\",\n",
    "        \"Exclusive deal for you: buy 2, get 1 free!!!\",\n",
    "        \"Download the report from https://reports.com.\",\n",
    "        \"The meeting is starting in 10 minutes.\",\n",
    "        \"Reminder: submit your timesheet by 5pm today.\"\n",
    "    ],\n",
    "    \"Label\": [\n",
    "        \"Inform\", \"Promo\", \"Inform\", \"Promo\",\n",
    "        \"Reminder\", \"Promo\", \"Inform\", \"Reminder\", \"Reminder\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2688a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # Replace URLs with special token\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' URL ', text)\n",
    "\n",
    "    # Replace numbers with special token\n",
    "    text = re.sub(r'\\b\\d+(\\.\\d+)?\\b', ' NUMBER ', text)\n",
    "\n",
    "    # Replace punctuation with special token\n",
    "    punct_pattern = f\"[{re.escape(string.punctuation)}]\"\n",
    "    text = re.sub(punct_pattern, ' PUNCT ', text)\n",
    "\n",
    "    # Tokenize (split by spaces)\n",
    "    tokens = text.split()\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d760c9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentence  \\\n",
      "0      Check out https://example.com for more info!   \n",
      "1       Order 3 items, get 1 free! Limited offer!!!   \n",
      "2         Your package #12345 will arrive tomorrow.   \n",
      "3         Win $1000 now, visit http://winbig.com!!!   \n",
      "4  Meeting at 3pm, don't forget to bring the files.   \n",
      "5      Exclusive deal for you: buy 2, get 1 free!!!   \n",
      "6     Download the report from https://reports.com.   \n",
      "7            The meeting is starting in 10 minutes.   \n",
      "8     Reminder: submit your timesheet by 5pm today.   \n",
      "\n",
      "                                        Preprocessed     Label  \n",
      "0                  check out URL for more info PUNCT    Inform  \n",
      "1  order NUMBER items PUNCT get NUMBER free PUNCT...     Promo  \n",
      "2  your package PUNCT NUMBER will arrive tomorrow...    Inform  \n",
      "3               win PUNCT NUMBER now PUNCT visit URL     Promo  \n",
      "4  meeting at 3pm PUNCT don PUNCT t forget to bri...  Reminder  \n",
      "5  exclusive deal for you PUNCT buy NUMBER PUNCT ...     Promo  \n",
      "6                       download the report from URL    Inform  \n",
      "7    the meeting is starting in NUMBER minutes PUNCT  Reminder  \n",
      "8  reminder PUNCT submit your timesheet by 5pm to...  Reminder  \n"
     ]
    }
   ],
   "source": [
    "df[\"Preprocessed\"] = df[\"Sentence\"].apply(preprocess)\n",
    "print(df[[\"Sentence\", \"Preprocessed\", \"Label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac16ab35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Feature Matrix:\n",
      "\n",
      "     3pm    5pm  arrive     at  bring    buy     by  check   deal    don  ...  \\\n",
      "0  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.429  0.000  0.000  ...   \n",
      "1  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "2  0.000  0.000   0.416  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "3  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "4  0.318  0.000   0.000  0.318  0.318  0.000  0.000  0.000  0.000  0.318  ...   \n",
      "5  0.000  0.000   0.000  0.000  0.000  0.289  0.000  0.000  0.289  0.000  ...   \n",
      "6  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "7  0.000  0.000   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  ...   \n",
      "8  0.000  0.367   0.000  0.000  0.000  0.000  0.367  0.000  0.000  0.000  ...   \n",
      "\n",
      "   timesheet     to  today  tomorrow    url  visit   will    win    you   your  \n",
      "0      0.000  0.000  0.000     0.000  0.315  0.000  0.000  0.000  0.000  0.000  \n",
      "1      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "2      0.000  0.000  0.000     0.416  0.000  0.000  0.416  0.000  0.000  0.352  \n",
      "3      0.000  0.000  0.000     0.000  0.343  0.467  0.000  0.467  0.000  0.000  \n",
      "4      0.000  0.318  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "5      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.289  0.000  \n",
      "6      0.000  0.000  0.000     0.000  0.364  0.000  0.000  0.000  0.000  0.000  \n",
      "7      0.000  0.000  0.000     0.000  0.000  0.000  0.000  0.000  0.000  0.000  \n",
      "8      0.367  0.000  0.367     0.000  0.000  0.000  0.000  0.000  0.000  0.310  \n",
      "\n",
      "[9 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Preprocessed\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(\"\\nTF-IDF Feature Matrix:\\n\")\n",
    "print(tfidf_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "295ea4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Preprocessed</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_number</th>\n",
       "      <th>has_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Check out https://example.com for more info!</td>\n",
       "      <td>Inform</td>\n",
       "      <td>check out URL for more info PUNCT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Order 3 items, get 1 free! Limited offer!!!</td>\n",
       "      <td>Promo</td>\n",
       "      <td>order NUMBER items PUNCT get NUMBER free PUNCT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Your package #12345 will arrive tomorrow.</td>\n",
       "      <td>Inform</td>\n",
       "      <td>your package PUNCT NUMBER will arrive tomorrow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Win $1000 now, visit http://winbig.com!!!</td>\n",
       "      <td>Promo</td>\n",
       "      <td>win PUNCT NUMBER now PUNCT visit URL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meeting at 3pm, don't forget to bring the files.</td>\n",
       "      <td>Reminder</td>\n",
       "      <td>meeting at 3pm PUNCT don PUNCT t forget to bri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentence     Label  \\\n",
       "0      Check out https://example.com for more info!    Inform   \n",
       "1       Order 3 items, get 1 free! Limited offer!!!     Promo   \n",
       "2         Your package #12345 will arrive tomorrow.    Inform   \n",
       "3         Win $1000 now, visit http://winbig.com!!!     Promo   \n",
       "4  Meeting at 3pm, don't forget to bring the files.  Reminder   \n",
       "\n",
       "                                        Preprocessed  has_url  has_number  \\\n",
       "0                  check out URL for more info PUNCT        0           0   \n",
       "1  order NUMBER items PUNCT get NUMBER free PUNCT...        0           0   \n",
       "2  your package PUNCT NUMBER will arrive tomorrow...        0           0   \n",
       "3               win PUNCT NUMBER now PUNCT visit URL        0           0   \n",
       "4  meeting at 3pm PUNCT don PUNCT t forget to bri...        0           0   \n",
       "\n",
       "   has_punct  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_features(text):\n",
    "    return {\n",
    "        \"has_url\": int(\"URL\" in text),\n",
    "        \"has_number\": int(\"NUMBER\" in text),\n",
    "        \"has_punct\": int(\"PUNCT\" in text)\n",
    "    }\n",
    "\n",
    "binary_feats = df[\"Preprocessed\"].apply(extract_features)\n",
    "binary_df = pd.DataFrame(list(binary_feats))\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df = pd.concat([df, binary_df], axis=1)\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "818db9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(tokens):\n",
    "    return [(tokens[i], tokens[i+1]) for i in range(len(tokens)-1)]\n",
    "\n",
    "# Build bigram counts per label\n",
    "bigram_counts = defaultdict(Counter)\n",
    "unigram_counts = defaultdict(Counter)\n",
    "labels = df[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fcf004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    tokens = row[\"Preprocessed\"].split()\n",
    "    label = row[\"Label\"]\n",
    "    for bg in get_bigrams(tokens):\n",
    "        bigram_counts[label][bg] += 1\n",
    "    for token in tokens:\n",
    "        unigram_counts[label][token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7191c2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(token for label in labels for token in unigram_counts[label])\n",
    "V = len(vocab)\n",
    "K = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f884729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Test: ['you', 'will', 'get', 'an', 'exclusive', 'offer', 'in', 'the', 'meeting', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"You will get an exclusive offer in the meeting!\"\n",
    "test_prep = preprocess(test_sentence)\n",
    "tokens = test_prep.split()\n",
    "print(\"Preprocessed Test:\", tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4e87e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_backoff_prob(tokens, label, K=0.3):\n",
    "    \"\"\"\n",
    "    Compute bigram probability with unigram backoff.\n",
    "    \"\"\"\n",
    "    prob = 1.0\n",
    "    V = len(vocab)\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        if i == 0:\n",
    "            # First token: use unigram probability\n",
    "            count_uni = unigram_counts[label][tokens[i]]\n",
    "            total_uni = sum(unigram_counts[label].values())\n",
    "            p = (count_uni + K) / (total_uni + K * V)\n",
    "        else:\n",
    "            bigram = (tokens[i-1], tokens[i])\n",
    "            count_bg = bigram_counts[label][bigram]\n",
    "            count_prev = unigram_counts[label][tokens[i-1]]\n",
    "            \n",
    "            if count_bg > 0:\n",
    "                # Seen bigram\n",
    "                p = (count_bg + K) / (count_prev + K * V)\n",
    "            else:\n",
    "                # Backoff to unigram\n",
    "                count_uni = unigram_counts[label][tokens[i]]\n",
    "                total_uni = sum(unigram_counts[label].values())\n",
    "                p = (count_uni + K) / (total_uni + K * V)\n",
    "                \n",
    "        prob *= p\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e753954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_priors = df[\"Label\"].value_counts(normalize=True).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "231e5aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label_backoff(tokens):\n",
    "    scores = {}\n",
    "    for label in labels:\n",
    "        score = np.log(label_priors[label])\n",
    "        score += np.log(bigram_backoff_prob(tokens, label))\n",
    "        scores[label] = score\n",
    "    return max(scores, key=scores.get), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b7c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"You will get an exclusive offer in the meeting!\"\n",
    "test_prep = preprocess(test_sentence)\n",
    "tokens = test_prep.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "623063be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Test: ['you', 'will', 'get', 'an', 'exclusive', 'offer', 'in', 'the', 'meeting', 'PUNCT']\n",
      "Predicted Label: Promo\n",
      "Label Scores: {'Inform': np.float64(-43.27516779107038), 'Promo': np.float64(-41.84566543246728), 'Reminder': np.float64(-42.13943206335457)}\n"
     ]
    }
   ],
   "source": [
    "pred_label, label_scores = predict_label_backoff(tokens)\n",
    "print(\"Preprocessed Test:\", tokens)\n",
    "print(\"Predicted Label:\", pred_label)\n",
    "print(\"Label Scores:\", label_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01d012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
