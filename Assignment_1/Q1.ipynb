{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMeYZeaPmdMsd2wz4lPBZa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarun02185/NLP/blob/main/Assignment_1/Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ICdgcHw4clv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "43a0ecd16604486da5edc52b89204b61",
            "fb207776c6d4418aab8d5359d5e002f7",
            "6368543f4df8419fb63070a6d3af9ef7",
            "ac5f2246fb564c63b704e0cad0ae50eb",
            "4177a80722304672b4f4a965e5151010",
            "a341760b10dd4509ae53c247fb9a87ce",
            "1354c455657241fdb0741c559765e60a",
            "14cfade3fca44f77ab7ed09ef420f848",
            "ab2f4e43403a4e58bab94283d1a74f5f",
            "e597429f28d94c48b5291afa15d2dc49",
            "85ca51b72ccf4045a5af16c9f38ceaf9"
          ]
        },
        "outputId": "b8360a9b-b15a-4d6b-ba12-2ceb3253c9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43a0ecd16604486da5edc52b89204b61"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ai4bharat/IndicCorpV2\", \"indiccorp_v2\", streaming = \"True\", split=\"hin_Deva\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def hindi_sentence_tokenizer(text):\n",
        "    return re.split(r'(?<=[।!?])\\s+', text)\n",
        "\n",
        "\n",
        "def hindi_word_tokenizer(text):\n",
        "    return re.findall(r'[\\u0900-\\u097F]+|\\d+|[.,!?]', text)\n",
        "\n",
        "\n",
        "N = 10\n",
        "for i, example in enumerate(dataset):\n",
        "    if i >= N:\n",
        "        break\n",
        "    text = example['text']\n",
        "    sentences = hindi_sentence_tokenizer(text)\n",
        "    for s in sentences:\n",
        "        words = hindi_word_tokenizer(s)\n",
        "        print(words)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEN4wIeNg9OG",
        "outputId": "236bca3e-19e0-4f18-8cd8-615f78063375"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['लोगों', 'को', 'बिलों', 'संबंधी', 'सुविधा', 'देना', 'ही', 'उनका', 'काम']\n",
            "[]\n",
            "['इनेलो', '1987', 'में', 'उस', 'वक्त', 'ऐसे', 'ही', 'दोराहे', 'पर', 'खड़ी', 'थी', ',', 'जब', 'पूर्व', 'उपप्रधानमंत्री', 'देवीलाल', 'ने', 'अपने', 'पुत्र', 'ओमप्रकाश', 'चौटाला', 'को', 'अपना', 'राजनीतिक', 'उत्तराधिकारी', 'घोषित', 'किया', 'था।']\n",
            "['हालांकि', 'तब', 'पार्टी', 'पर', 'देवीलाल', 'की', 'मजबूत', 'पकड़', 'के', 'चलते', 'पार्टी', 'टूटने', 'से', 'बच', 'गई', 'थी।']\n",
            "['1989', 'में', 'देवीलाल', 'केन्द्र', 'की', 'राजनीति', 'में', 'सक्रिय', 'हो', 'गए', 'थे', 'और', 'उनके', 'उपप्रधानमंत्री', 'बनने', 'के', 'पश्चात्', 'उनके', 'तीन', 'बेटों', 'जगदीश', 'सिंह', ',', 'रणजीत', 'सिंह', 'और', 'ओमप्रकाश', 'चौटाला', 'में', 'से', 'रणजीत', 'और', 'ओमप्रकाश', 'के', 'बीच', 'हरियाणा', 'में', 'उनकी', 'राजनीतिक', 'विरासत', 'को', 'लेकर', 'जंग', 'शुरू', 'हो', 'गई', 'थी।']\n",
            "['उन', 'परिस्थितियों', 'में', 'देवीलाल', 'ने', 'कड़ा', 'निर्णय', 'लेते', 'हुए', 'पार्टी', 'की', 'बागडोर', 'ओमप्रकाश', 'चौटाला', 'के', 'हवाले', 'कर', 'दी', 'थी', ',', 'जिसके', 'बाद', 'रणजीत', 'की', 'बगावत', 'का', 'असर', 'पार्टी', ',', 'संगठन', 'और', 'उनकी', 'सरकार', 'पर', 'भी', 'पड़ा', 'था।']\n",
            "['उस', 'समय', 'रणजीत', 'की', 'नाराजगी', 'के', 'चलते', 'उनके', 'समर्थन', 'में', 'कई', 'कैबिनेट', 'मंत्रियों', 'ने', 'इस्तीफे', 'दे', 'दिए', 'थे', 'किन्तु', 'तब', 'पार्टी', 'सुप्रीमो', 'चौ', '.', 'देवीलाल', 'की', 'हरियाणा', 'की', 'जनता', 'पर', 'इतनी', 'मजबूत', 'पकड़', 'थी', 'कि', 'ओमप्रकाश', 'चौटाला', 'को', 'उत्तराधिकारी', 'बनाने', 'के', 'उनके', 'फैसले', 'का', 'जनता', 'के', 'बीच', 'कोई', 'खास', 'विरोध', 'नहीं', 'हुआ', 'था', 'लेकिन', 'आज', 'स्थिति', 'बिल्कुल', 'विपरीत', 'है।']\n",
            "['ओमप्रकाश', 'चौटाला', 'पिछले', 'काफी', 'समय', 'से', 'जेल', 'में', 'हैं', 'और', 'जेल', 'में', 'रहते', 'पार्टी', 'के', 'साथ', 'साथ', 'परिवार', 'पर', 'भी', 'उनकी', 'पकड़', 'काफी', 'ढ़ीली', 'हो', 'गई', 'है', ',', 'इसी', 'कारण', 'उनमें', 'अब', 'देवीलाल', 'जैसा', 'वो', 'सामर्थ्य', 'नजर', 'नहीं', 'आता', 'कि', 'वे', 'अपने', 'फैसलों', 'को', 'बगैर', 'किसी', 'प्रतिरोध', 'के', 'लागू', 'करा', 'सकें।']\n",
            "[]\n",
            "['जहां', 'आई', 'थी', 'तबाही', 'उस', 'घाटी', 'क्षेत्र', 'में', 'खतरा', 'ज्यादा']\n",
            "[]\n",
            "['इसके', 'बाद', 'केंद्र', 'की', 'ओर', 'से', 'प्रदेश', 'सरकार', 'को', 'पीएमजीएसवाई', 'में', '200', 'करोड़', 'रुपये', 'की', 'राशि', 'उपलब्ध', 'करा', 'दी', 'गई।']\n",
            "['भाजपा', 'के', 'मीडिया', 'प्रभारी', 'दिवाकर', 'सिंह', 'ने', 'शनिवार', 'को', 'बताया', 'कि', 'केंद्र', 'ने', 'प्रदेश', 'सरकार', 'को', '200', 'करोड़', 'रुपये', 'भेजा', 'है।']\n",
            "[]\n",
            "['यह', 'पूछने', 'पर', 'कि', 'इस', 'बड़े', 'मैच', 'से', 'पहले', 'उनकी', 'नींद', 'गायब', 'हुई', 'तो', 'बाबर', 'ने', 'कहा', ',', 'हम', 'काफी', 'टूर्नामेंट', 'खेल', 'चुके', 'हैं', ',', 'हमने', 'चैम्पियंस', 'ट्राफी', 'में', 'भी', 'अच्छा', 'किया', 'था', '.', 'हम', 'इसे', 'जितना', 'सरल', 'रखेंगे', ',', 'उतना', 'ही', 'बेहतर', 'होगा', '.', 'इसमें', 'सिर्फ', 'बेसिक्स', 'पर', 'अडिग', 'रहना', 'होगा', 'और', 'साथ', 'ही', 'शांत', 'चित्त', 'बने', 'रहना', 'होगा', '.', 'हमारी', 'तैयारी', 'हमारे', 'हाथों', 'में', 'हैं', 'और', 'हमने', 'अपना', 'शत', 'प्रतिशत', 'दिया', 'है', '.', 'हमें', 'मैच', 'के', 'दिन', 'अच्छी', 'क्रिकेट', 'खेलने', 'की', 'उम्मीद', 'है', '.']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_file = \"tokens_of_hindi_corpus.txt\"\n",
        "sentences_file = \"sentences_of_hindi_corpus.txt\"\n",
        "\n",
        "\n",
        "N = 100\n",
        "\n",
        "\n",
        "total_sentences = 0\n",
        "total_words = 0\n",
        "total_chars = 0\n",
        "unique_word_tokens = set()\n",
        "\n",
        "processed_paragraphs = 0\n",
        "\n",
        "with open(tokens_file, \"w\", encoding=\"utf-8\") as tf, open(sentences_file, \"w\", encoding=\"utf-8\") as sf:\n",
        "    for example in dataset:\n",
        "        if processed_paragraphs >= N:\n",
        "            break\n",
        "\n",
        "        text = example.get(\"text\", \"\").strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        sentences = hindi_sentence_tokenizer(text)\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if not sentence:\n",
        "                continue\n",
        "\n",
        "            words = hindi_word_tokenizer(sentence)\n",
        "            if not words:\n",
        "                continue\n",
        "\n",
        "            tokenized_sentence = \" \".join(words)\n",
        "            sf.write(tokenized_sentence + \"\\n\")\n",
        "\n",
        "            total_sentences += 1\n",
        "            total_words += len(words)\n",
        "            total_chars += sum(len(w) for w in words)\n",
        "\n",
        "            for w in words:\n",
        "                tf.write(w + \"\\n\")\n",
        "                unique_word_tokens.add(w)\n",
        "\n",
        "        processed_paragraphs += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "avg_sentence_length = total_words / total_sentences\n",
        "avg_word_length = total_chars / total_words\n",
        "ttr = len(unique_word_tokens) / total_words\n",
        "\n",
        "\n",
        "\n",
        "print(f\"1. Total number of sentences: {total_sentences}\")\n",
        "print(f\"2. Total number of words: {total_words}\")\n",
        "print(f\"3a. Total characters : {total_chars}\")\n",
        "print(f\"4. Average sentence length : {avg_sentence_length:.2f}\")\n",
        "print(f\"5. Average word length : {avg_word_length:.2f}\")\n",
        "print(f\"6. Type/Token Ratio (TTR): {ttr:.4f}\")\n",
        "print(f\"   → Unique word tokens: {len(unique_word_tokens)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i0T5PQMRZLb",
        "outputId": "9bbbe24e-294e-475e-d47e-8fb15a5a9ae1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Total number of sentences: 251\n",
            "2. Total number of words: 5865\n",
            "3a. Total characters : 22318\n",
            "4. Average sentence length : 23.37\n",
            "5. Average word length : 3.81\n",
            "6. Type/Token Ratio (TTR): 0.3538\n",
            "   → Unique word tokens: 2075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufDbZU4fEA7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
